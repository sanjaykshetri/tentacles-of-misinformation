{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb526a",
   "metadata": {},
   "source": [
    "# Sprint 2: Baseline NLP Models\n",
    "\n",
    "**Objective**: Establish strong classical NLP baselines using TF-IDF vectorization with Logistic Regression and Linear SVM.\n",
    "\n",
    "**Key Components**:\n",
    "- Stratified train/validation split to preserve class distribution\n",
    "- Class-weighted models to handle 3.2:1 imbalance\n",
    "- Comprehensive evaluation: confusion matrices, ROC-AUC, precision-recall\n",
    "- Error analysis to identify systematic failure modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576342e9",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f334d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, auc, precision_recall_curve, accuracy_score, f1_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c94839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet(\"../../data/processed/articles.parquet\")\n",
    "df[\"label_num\"] = (df[\"label\"] == \"fake\").astype(int)\n",
    "\n",
    "print(f\"Loaded {len(df)} articles\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b3759",
   "metadata": {},
   "source": [
    "## 2. Stratified Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split to preserve class balance\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"title\"],\n",
    "    df[\"label_num\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label_num\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train):,}\")\n",
    "print(f\"Val size: {len(X_val):,}\")\n",
    "print(f\"\\nTrain class distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(f\"\\nVal class distribution:\")\n",
    "print(pd.Series(y_val).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79926376",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9608589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "\n",
    "print(f\"Vectorizer fitted on {len(vectorizer.vocabulary_):,} unique terms\")\n",
    "print(f\"Train matrix shape: {X_train_vec.shape}\")\n",
    "print(f\"Val matrix shape: {X_val_vec.shape}\")\n",
    "print(f\"\\nSparsity: {1 - (X_train_vec.nnz / (X_train_vec.shape[0] * X_train_vec.shape[1])):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1d07f",
   "metadata": {},
   "source": [
    "## 4. Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with class weights\n",
    "print(\"Training Logistic Regression with class_weight='balanced'...\\n\")\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "logreg.fit(X_train_vec, y_train)\n",
    "print(\"‚úÖ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "y_pred_logreg = logreg.predict(X_val_vec)\n",
    "y_pred_proba_logreg = logreg.predict_proba(X_val_vec)[:, 1]\n",
    "roc_auc_logreg = roc_auc_score(y_val, y_pred_proba_logreg)\n",
    "f1_logreg = f1_score(y_val, y_pred_logreg)\n",
    "accuracy_logreg = accuracy_score(y_val, y_pred_logreg)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOGISTIC REGRESSION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {accuracy_logreg:.4f}\")\n",
    "print(f\"F1 Score: {f1_logreg:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_logreg:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_logreg, target_names=[\"Real\", \"Fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd59b33",
   "metadata": {},
   "source": [
    "## 5. Train Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9101708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM with class weights\n",
    "print(\"Training Linear SVM with class_weight='balanced'...\\n\")\n",
    "\n",
    "svm = LinearSVC(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=3000,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "svm.fit(X_train_vec, y_train)\n",
    "print(\"‚úÖ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear SVM\n",
    "y_pred_svm = svm.predict(X_val_vec)\n",
    "y_scores_svm = svm.decision_function(X_val_vec)\n",
    "y_pred_proba_svm = 1 / (1 + np.exp(-y_scores_svm))  # sigmoid transformation\n",
    "roc_auc_svm = roc_auc_score(y_val, y_scores_svm)\n",
    "f1_svm = f1_score(y_val, y_pred_svm)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LINEAR SVM RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_svm:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_svm:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_svm, target_names=[\"Real\", \"Fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6212ad6",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4aeb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Linear SVM'],\n",
    "    'Accuracy': [accuracy_logreg, accuracy_svm],\n",
    "    'F1 Score': [f1_logreg, f1_svm],\n",
    "    'ROC-AUC': [roc_auc_logreg, roc_auc_svm]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Highlight winner\n",
    "best_model = 'Logistic Regression' if roc_auc_logreg > roc_auc_svm else 'Linear SVM'\n",
    "print(f\"\\n‚ú® Best Model (ROC-AUC): {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7380ea7",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "cm_logreg = confusion_matrix(y_val, y_pred_logreg)\n",
    "cm_svm = confusion_matrix(y_val, y_pred_svm)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'],\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Confusion Matrix - Logistic Regression', fontweight='bold', fontsize=12)\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Linear SVM\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'],\n",
    "            ax=axes[1], cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title('Confusion Matrix - Linear SVM', fontweight='bold', fontsize=12)\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "tn, fp, fn, tp = cm_logreg.ravel()\n",
    "print(f\"\\nLogistic Regression Confusion Matrix Breakdown:\")\n",
    "print(f\"  True Negatives (Real, predicted Real): {tn:,}\")\n",
    "print(f\"  False Positives (Real, predicted Fake): {fp:,}\")\n",
    "print(f\"  False Negatives (Fake, predicted Real): {fn:,}\")\n",
    "print(f\"  True Positives (Fake, predicted Fake): {tp:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1ba87",
   "metadata": {},
   "source": [
    "## 8. ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_val, y_pred_proba_logreg)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_val, y_pred_proba_svm)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# LogReg ROC\n",
    "axes[0].plot(fpr_logreg, tpr_logreg, color='darkorange', lw=2, \n",
    "            label=f'Logistic Regression (AUC = {roc_auc_logreg:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve - Logistic Regression', fontweight='bold')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# SVM ROC\n",
    "axes[1].plot(fpr_svm, tpr_svm, color='green', lw=2, \n",
    "            label=f'Linear SVM (AUC = {roc_auc_svm:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve - Linear SVM', fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curves\n",
    "precision_logreg, recall_logreg, _ = precision_recall_curve(y_val, y_pred_proba_logreg)\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_val, y_pred_proba_svm)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# LogReg PR\n",
    "axes[0].plot(recall_logreg, precision_logreg, color='darkorange', lw=2, label='Logistic Regression')\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision-Recall Curve - Logistic Regression', fontweight='bold')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].legend(loc=\"best\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# SVM PR\n",
    "axes[1].plot(recall_svm, precision_svm, color='green', lw=2, label='Linear SVM')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve - Linear SVM', fontweight='bold')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].legend(loc=\"best\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034dc50",
   "metadata": {},
   "source": [
    "## 9. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis for Logistic Regression\n",
    "errors_logreg = pd.DataFrame({\n",
    "    'title': X_val.values,\n",
    "    'true_label': y_val.values,\n",
    "    'pred_label': y_pred_logreg,\n",
    "    'confidence': np.abs(y_pred_proba_logreg - 0.5) + 0.5\n",
    "})\n",
    "\n",
    "# False positives\n",
    "false_pos = errors_logreg[(errors_logreg.true_label == 0) & (errors_logreg.pred_label == 1)]\n",
    "print(\"=\"*70)\n",
    "print(f\"FALSE POSITIVES (Real ‚Üí Fake): {len(false_pos):,} samples\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTop examples (by confidence):\")\n",
    "for idx, row in false_pos.nlargest(5, 'confidence').iterrows():\n",
    "    print(f\"\\n  ‚Ä¢ {row['title'][:80]}...\")\n",
    "    print(f\"    Confidence: {row['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negatives\n",
    "false_neg = errors_logreg[(errors_logreg.true_label == 1) & (errors_logreg.pred_label == 0)]\n",
    "print(\"=\"*70)\n",
    "print(f\"FALSE NEGATIVES (Fake ‚Üí Real): {len(false_neg):,} samples\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTop examples (by confidence):\")\n",
    "for idx, row in false_neg.nlargest(5, 'confidence').iterrows():\n",
    "    print(f\"\\n  ‚Ä¢ {row['title'][:80]}...\")\n",
    "    print(f\"    Confidence: {row['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714a40b",
   "metadata": {},
   "source": [
    "## 10. Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18448ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KEY INSIGHTS FROM BASELINE MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ PERFORMANCE:\n",
    "   - Logistic Regression outperforms Linear SVM (ROC-AUC: 0.859 vs 0.841)\n",
    "   - Both models achieve ~81% accuracy on validation set\n",
    "   - Reasonable F1 scores (~0.64) given class imbalance\n",
    "\n",
    "‚ö†Ô∏è  FAILURE PATTERNS:\n",
    "   - False Positives ({len(false_pos):,} real articles misclassified as fake):\n",
    "     ‚Üí Often entertainment/celebrity content\n",
    "     ‚Üí Real articles with sensational phrasing\n",
    "   \n",
    "   - False Negatives ({len(false_neg):,} fake articles misclassified as real):\n",
    "     ‚Üí Music/award show titles (neutral phrasing)\n",
    "     ‚Üí Listicles and ranking content\n",
    "     ‚Üí Often from GossipCop (entertainment-only domain)\n",
    "\n",
    "üí° IMPLICATIONS:\n",
    "   - Domain difference (Politifact vs GossipCop) matters\n",
    "   - Title-only features insufficient for robust classification\n",
    "   - Need richer linguistic features (emotion, subjectivity, readability)\n",
    "   - Next: Add behavioral features from Sprint 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1aa20",
   "metadata": {},
   "source": [
    "## 11. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015795b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models are already saved via the training script\n",
    "# But we can verify and use them here\n",
    "\n",
    "print(\"‚úÖ Models and vectorizer ready for deployment\")\n",
    "print(\"\\nSaved artifacts:\")\n",
    "print(\"  - models/logistic_regression.joblib\")\n",
    "print(\"  - models/linear_svm.joblib\")\n",
    "print(\"  - models/tfidf_vectorizer.joblib\")\n",
    "print(\"\\nResults:\")\n",
    "print(\"  - results/cm_logistic_regression.png\")\n",
    "print(\"  - results/roc_logistic_regression.png\")\n",
    "print(\"  - results/pr_logistic_regression.png\")\n",
    "print(\"  - results/cm_linear_svm.png\")\n",
    "print(\"  - results/roc_linear_svm.png\")\n",
    "print(\"  - results/pr_linear_svm.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
